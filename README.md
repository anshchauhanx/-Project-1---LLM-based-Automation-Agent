# LLM-based Automation Agent

## ğŸš€ Project Overview
This project is an **LLM-based Automation Agent** that can execute various operational and business tasks using a **FastAPI**-based REST API. The agent takes plain-English tasks, processes them using an **LLM (via IITM Proxy API)**, and performs multi-step automation.

## ğŸ“Œ Features
- âœ… **Execute English-language tasks** using `/run?task=...`
- âœ… **Read output files** using `/read?path=...`
- âœ… **Supports various automation tasks** (file operations, API requests, database queries, and more)
- âœ… **Runs inside a Docker container** and can be deployed with **Podman**

## ğŸ› ï¸ Tech Stack
- **Python 3.11**
- **FastAPI** (REST API framework)
- **SQLite3** (Database operations)
- **OpenAI API via IITM Proxy** (for task processing)
- **Docker & Podman** (for containerization)

---

## ğŸ“‚ Project Structure
```
llm-automation-agent/
â”‚-- app/
â”‚   â”œâ”€â”€ main.py       # FastAPI entry point
â”‚   â”œâ”€â”€ tasks.py      # Handles task execution
â”‚   â”œâ”€â”€ llm.py        # Communicates with IITM Proxy API
â”‚-- data/             # Folder for generated output files
â”‚-- create_db.py      # Script to initialize SQLite database
â”‚-- Dockerfile        # Container setup
â”‚-- .env              # API key configuration
â”‚-- requirements.txt  # Python dependencies
â”‚-- README.md         # Project documentation
```

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/anshchauhanx/-Project-1---LLM-based-Automation-Agent.git
cd llm-automation-agent
```

### 2ï¸âƒ£ Install Dependencies
```sh
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set Up Environment Variables
Create a `.env` file and add your **IITM Proxy API key**:
```
AIPROXY_TOKEN=your_iitm_proxy_api_key
```

### 4ï¸âƒ£ Run the FastAPI Server
```sh
uvicorn app.main:app --reload
```
âœ… API will be available at: **http://127.0.0.1:8000**

### 5ï¸âƒ£ Test API Endpoints
#### **Run a Task**
```powershell
Invoke-RestMethod -Uri "http://127.0.0.1:8000/run?task=count%20Wednesdays%20in%20/data/dates.txt" -Method Post
```
#### **Read a File**
```powershell
Invoke-RestMethod -Uri "http://127.0.0.1:8000/read?path=/data/dates-wednesdays.txt" -Method Get
```

---

## ğŸ³ Docker Deployment
### 1ï¸âƒ£ Build the Docker Image
```sh
docker build -t anshchauhanx/llm-automation-agent .
```

### 2ï¸âƒ£ Push to Docker Hub
```sh
docker login
docker tag anshchauhanx/llm-automation-agent anshchauhanx/llm-automation-agent:latest
docker push anshchauhanx/llm-automation-agent:latest
```

### 3ï¸âƒ£ Run the Image with Podman
```sh
podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000 docker.io/anshchauhanx/llm-automation-agent:latest
```
âœ… **API will be available at:** `http://localhost:8000`

---

## ğŸ“œ License
This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

ğŸš€ **Happy Coding!** ğŸ‰
